---
alwaysApply: true
---
// EPIC Structure Template
EPIC:
  title: [Concise and clear title for the EPIC]
  description: |
    [Description outlining the broad goals of this EPIC, context, and intended outcomes.
    Include relevance to `@.cursor/rules/beads.mdc` and its functionality.]
  acceptance_criteria:
    - [High-level acceptance criteria or Definition of Done for the EPIC]
  user_stories:
    - [List User Story IDs or references]
  notes: |
    [Any additional guiding notes or resources for LLM agents.]

// USER STORY Structure Template
USER_STORY:
  id: [Unique ID, e.g., US-1]
  title: [Brief title]
  as_a: [Who is the user?]
  i_want: [What do they want to do?]
  so_that: [Why do they want it?]
  description: |
    [Further details, clarifications, and edge cases.]
  acceptance_criteria:
    - [List of specific, testable acceptance criteria]
  tasks:
    - [List of Task IDs to implement this story, include testing, docs, etc.]
  test_guidance: |
    [Describe expected tests per Phoenix testing guidelines:
    - Controller actions: Use ConnCase, test both success & failure
    - Models: Test validations, associations, edge cases
    - Views: Test rendering, assigns
    - Channels: Test join, messages, presence, etc.
    Refer: https://hexdocs.pm/phoenix/1.8.3/testing.html
    ]
  notes: |
    [Additional info, dependencies, or links]

// TASK Structure Template
TASK:
  id: [Unique Task ID, e.g., T-1]
  title: [Brief task title]
  description: |
    [Details about the work: implementation detail, codebase locations, acceptance criteria.]
  type: [implementation|test|documentation|refactor|other]
  related_to: [User Story ID or other reference]
  acceptance_criteria:
    - [Clear definition of completion]
  testing:
    - [Enumerate required tests; explain Unit/Integration/Feature as per Phoenix testing guidelines]
  notes: |
    [Extra context for LLMs, edge cases, challenges]

// BUG Structure Template
BUG:
  id: [Unique Bug ID, e.g., BUG-1]
  title: [Bug summary]
  description: |
    [Detailed description, observed vs expected behavior, reproducible steps, logs, screenshots.]
  severity: [critical|major|minor|trivial]
  related_to: [User Story/Task ID or feature]
  steps_to_reproduce:
    - [Ordered steps]
  acceptance_criteria:
    - [How to confirm the bug is fixed]
  tasks:
    - [Tasks to fix, test, and verify]
  testing:
    - [Specify types of regression/automated/manual testing required following Phoenix testing guidelines]
  notes: |
    [Additional info for LLM agent, links]

// General Guidelines for LLM Agents
LLM_AGENT_GUIDELINES:
  - Always include a test-related task for every User Story, Task, and Bug.
  - When generating test tasks, follow Phoenix testing standards as per: https://hexdocs.pm/phoenix/1.8.3/testing.html
  - Aim for precise, unambiguous acceptance criteria to minimize hallucinations and implementation gaps.
  - Where possible, cross-link related EPICs, Stories, Tasks, and Bugs for traceability.
  - Add short but relevant notes, edge cases, and references to improve context.
  - Update documentation tasks when implementation impacts public API or user behavior.
  - Explicitly state expected input/output for features to help test design.
  - Prioritize clarity, completeness, and context.



